{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic-to-CSV-Generator\n",
    "\n",
    "In this Jupyter-Notebook the reviews were transformed into topics. There are intermediate steps that should save the results in between as json-files. Currently, they are commented out, but they can be activated if needed.\n",
    "\n",
    "**Content:**\n",
    "- Importing packages\n",
    "- Read the data\n",
    "- 0 Split Sentences\n",
    "- 1 Tokenize Words in Sentences\n",
    "- 2 Remove Punctuation\n",
    "- 3.1 Train POS-Tagging\n",
    "- 3.2 Save POS-Tagging\n",
    "- 3.3 Load POS-Tagging\n",
    "- 3.4 Apply POS-Tagging\n",
    "- 4 Lemmatize based on POS-Tagging\n",
    "- 5 Lower Lemmas\n",
    "- 6 Remove Stopwords from Lemmas (and some others)\n",
    "- 7 Compress Dataset\n",
    "- 8 Saving to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import random \n",
    "#import numpy as np\n",
    "#nltk.download(\"punkt\")\n",
    "import string\n",
    "exclude = set(string.punctuation)\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag.sequential import ClassifierBasedTagger\n",
    "\n",
    "### from https://github.com/ptnplanet/NLTK-Contributions/tree/master/ClassifierBasedGermanTagger\n",
    "\n",
    "class ClassifierBasedGermanTagger(ClassifierBasedTagger):\n",
    "    \"\"\"A classifier based German part-of-speech tagger. It has an accuracy of\n",
    "    96.09% after being trained on 90% of the German TIGER corpus. The tagger\n",
    "    extends the NLTK ClassifierBasedTagger and implements a slightly modified\n",
    "    feature detector.\n",
    "    \"\"\"\n",
    "\n",
    "    def feature_detector(self, tokens, index, history):\n",
    "        \"\"\"Implementing a slightly modified feature detector.\n",
    "        @param tokens: The tokens from the sentence to tag.\n",
    "        @param index: The current token index to tag.\n",
    "        @param history: The previous tagged tokens.\n",
    "        \"\"\"\n",
    "\n",
    "        word = tokens[index]\n",
    "        if index == 0: # At the beginning of the sentence\n",
    "            prevword = prevprevword = None\n",
    "            prevtag = prevprevtag = None\n",
    "            #word = word.lower() # Lowercase at the beginning of sentence\n",
    "        elif index == 1:\n",
    "            prevword = tokens[index-1] # Note: no lowercase\n",
    "            prevprevword = None\n",
    "            prevtag = history[index-1]\n",
    "            prevprevtag = None\n",
    "        else:\n",
    "            prevword = tokens[index-1]\n",
    "            prevprevword = tokens[index-2]\n",
    "            prevtag = history[index-1]\n",
    "            prevprevtag = history[index-2]\n",
    "\n",
    "        if re.match('[0-9]+([\\.,][0-9]*)?|[0-9]*[\\.,][0-9]+$', word):\n",
    "            # Included \",\" as decimal point\n",
    "            shape = 'number'\n",
    "        elif re.compile('\\W+$', re.UNICODE).match(word):\n",
    "            # Included unicode flag\n",
    "            shape = 'punct'\n",
    "        elif re.match('([A-ZÄÖÜ]+[a-zäöüß]*-?)+$', word):\n",
    "            # Included dash for dashed words and umlauts\n",
    "            shape = 'upcase'\n",
    "        elif re.match('[a-zäöüß]+', word):\n",
    "            # Included umlauts\n",
    "            shape = 'downcase'\n",
    "        elif re.compile(\"\\w+\", re.UNICODE).match(word):\n",
    "            # Included unicode flag\n",
    "            shape = 'mixedcase'\n",
    "        else:\n",
    "            shape = 'other'\n",
    "\n",
    "        features = {\n",
    "            'prevtag': prevtag,\n",
    "            'prevprevtag': prevprevtag,\n",
    "            'word': word,\n",
    "            'word.lower': word.lower(),\n",
    "            'suffix3': word.lower()[-3:],\n",
    "            #'suffix2': word.lower()[-2:],\n",
    "            #'suffix1': word.lower()[-1:],\n",
    "            'preffix1': word[:1], # included\n",
    "            'prevprevword': prevprevword,\n",
    "            'prevword': prevword,\n",
    "            'prevtag+word': '%s+%s' % (prevtag, word),\n",
    "            'prevprevtag+word': '%s+%s' % (prevprevtag, word),\n",
    "            'prevword+word': '%s+%s' % (prevword, word),\n",
    "            'shape': shape\n",
    "            }\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StyleID</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1709054</td>\n",
       "      <td>Die sind okay und dann für den Preis.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709054</td>\n",
       "      <td>Qualität und Preis sind gut. Leider sind sie z...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8623725</td>\n",
       "      <td>lässt schlanker aussehen</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8623725</td>\n",
       "      <td>Material und Farbe gut. Da einige Kundinnen in...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9743730</td>\n",
       "      <td>Material ist schön zum verdunkel.  Leider doch...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StyleID                                               text  rating\n",
       "0  1709054             Die sind okay und dann für den Preis.        5\n",
       "1  1709054  Qualität und Preis sind gut. Leider sind sie z...       3\n",
       "2  8623725                           lässt schlanker aussehen       5\n",
       "3  8623725  Material und Farbe gut. Da einige Kundinnen in...       3\n",
       "4  9743730  Material ist schön zum verdunkel.  Leider doch...       5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Datensatz_Coding_Challenge.csv', delimiter=\";\")\n",
    "corpus = data.copy()\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Split Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/19150 [00:00<?, ?it/s]C:\\Users\\laris\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "100%|████████████████████████████████████████████████████████████████████████████| 19150/19150 [34:06<00:00,  9.08it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(corpus[\"text\"]))):\n",
    "    corpus[\"text\"][i] = nltk.sent_tokenize(corpus[\"text\"][i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus.to_json(r'00sentences.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StyleID</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1709054</td>\n",
       "      <td>[Die sind okay und dann für den Preis.]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709054</td>\n",
       "      <td>[Qualität und Preis sind gut., Leider sind sie...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8623725</td>\n",
       "      <td>[lässt schlanker aussehen]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8623725</td>\n",
       "      <td>[Material und Farbe gut., Da einige Kundinnen ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9743730</td>\n",
       "      <td>[Material ist schön zum verdunkel., Leider doc...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StyleID                                               text  rating\n",
       "0  1709054            [Die sind okay und dann für den Preis.]       5\n",
       "1  1709054  [Qualität und Preis sind gut., Leider sind sie...       3\n",
       "2  8623725                         [lässt schlanker aussehen]       5\n",
       "3  8623725  [Material und Farbe gut., Da einige Kundinnen ...       3\n",
       "4  9743730  [Material ist schön zum verdunkel., Leider doc...       5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Tokenize Words in Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 19150/19150 [00:32<00:00, 586.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(corpus[\"text\"]))):\n",
    "    for j in range(len(corpus[\"text\"][i])):\n",
    "        corpus[\"text\"][i][j] = nltk.word_tokenize(corpus[\"text\"][i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus.to_json(r'01tokenized.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StyleID</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1709054</td>\n",
       "      <td>[[Die, sind, okay, und, dann, für, den, Preis,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709054</td>\n",
       "      <td>[[Qualität, und, Preis, sind, gut, .], [Leider...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8623725</td>\n",
       "      <td>[[lässt, schlanker, aussehen]]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8623725</td>\n",
       "      <td>[[Material, und, Farbe, gut, .], [Da, einige, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9743730</td>\n",
       "      <td>[[Material, ist, schön, zum, verdunkel, .], [L...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StyleID                                               text  rating\n",
       "0  1709054  [[Die, sind, okay, und, dann, für, den, Preis,...       5\n",
       "1  1709054  [[Qualität, und, Preis, sind, gut, .], [Leider...       3\n",
       "2  8623725                     [[lässt, schlanker, aussehen]]       5\n",
       "3  8623725  [[Material, und, Farbe, gut, .], [Da, einige, ...       3\n",
       "4  9743730  [[Material, ist, schön, zum, verdunkel, .], [L...       5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 19150/19150 [00:04<00:00, 3929.68it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(corpus[\"text\"]))):\n",
    "    for j in range(len(corpus[\"text\"][i])):\n",
    "        corpus[\"text\"][i][j] = [token for token in corpus[\"text\"][i][j] if token not in \n",
    "                             exclude and token.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus.to_json(r'02punctuation.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StyleID</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1709054</td>\n",
       "      <td>5</td>\n",
       "      <td>[[Die, sind, okay, und, dann, für, den, Preis]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709054</td>\n",
       "      <td>3</td>\n",
       "      <td>[[Qualität, und, Preis, sind, gut], [Leider, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>709229</td>\n",
       "      <td>5</td>\n",
       "      <td>[[Angenehmer, Stoff], [Füllt, sich, gut, auf, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>709229</td>\n",
       "      <td>5</td>\n",
       "      <td>[[Angenehmes, und, pflegeleichtes, Material], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>9743730</td>\n",
       "      <td>1</td>\n",
       "      <td>[[ACHTUNG, Die, Stofffarbe, creme, ist, nicht,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      StyleID  rating                                               text\n",
       "0     1709054       5    [[Die, sind, okay, und, dann, für, den, Preis]]\n",
       "1     1709054       3  [[Qualität, und, Preis, sind, gut], [Leider, s...\n",
       "10     709229       5  [[Angenehmer, Stoff], [Füllt, sich, gut, auf, ...\n",
       "100    709229       5  [[Angenehmes, und, pflegeleichtes, Material], ...\n",
       "1000  9743730       1  [[ACHTUNG, Die, Stofffarbe, creme, ist, nicht,..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Train POS-Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of code is needed to create \"nltk_german_classifier_data.pickle\". As this was done already, this code is not necessary for the whole code to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-48c495b46839>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m corp = nltk.corpus.ConllCorpusReader('.', 'tiger_release_aug07.corrected.16012013.conll09',\n\u001b[0m\u001b[0;32m      2\u001b[0m                                     \u001b[1;33m[\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'words'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pos'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                     encoding='utf-8')\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "#corp = nltk.corpus.ConllCorpusReader('.', 'tiger_release_aug07.corrected.16012013.conll09',\n",
    "#                                    ['ignore', 'words', 'ignore', 'ignore', 'pos'],\n",
    "#                                    encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tagged_sents = corp.tagged_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tagged_sents2 = [sentence for sentence in tagged_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(tagged_sents2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.shuffle(tagged_sents2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_perc = 0.1\n",
    "#split_size = int(len(tagged_sents) * split_perc)\n",
    "#train_sents, test_sents = tagged_sents2[split_size:], tagged_sents2[:split_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tagger = ClassifierBasedGermanTagger(train=train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy = tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9418093958519154\n"
     ]
    }
   ],
   "source": [
    "#print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ich', 'PPER'),\n",
       " ('schreibe', 'VVFIN'),\n",
       " ('gerade', 'ADV'),\n",
       " ('an', 'APPR'),\n",
       " ('meiner', 'PPOSAT'),\n",
       " ('Thesis', 'NN')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tagger.tag(['Ich', 'schreibe', 'gerade', 'an', 'meiner', 'Thesis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Save POS-Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVING\n",
    "#with open(\"nltk_german_classifier_data.pickle\", \"wb\") as f:\n",
    "#    pickle.dump(tagger, f, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Load POS-Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOADING\n",
    "with open('nltk_german_classifier_data.pickle', 'rb') as f:\n",
    "    tagger = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Apply POS-Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 19150/19150 [22:55<00:00, 13.92it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(corpus[\"text\"]))):\n",
    "    for j in range(len(corpus[\"text\"][i])):\n",
    "        corpus[\"text\"][i][j] = tagger.tag(corpus[\"text\"][i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus.to_json(r'03pos-tagged.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StyleID</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1709054</td>\n",
       "      <td>5</td>\n",
       "      <td>[[(Die, ART), (sind, VAFIN), (okay, ADJD), (un...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709054</td>\n",
       "      <td>3</td>\n",
       "      <td>[[(Qualität, NN), (und, KON), (Preis, NN), (si...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>709229</td>\n",
       "      <td>5</td>\n",
       "      <td>[[(Angenehmer, NE), (Stoff, NN)], [(Füllt, NE)...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>709229</td>\n",
       "      <td>5</td>\n",
       "      <td>[[(Angenehmes, NE), (und, KON), (pflegeleichte...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>9743730</td>\n",
       "      <td>1</td>\n",
       "      <td>[[(ACHTUNG, NN), (Die, ART), (Stofffarbe, NN),...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      StyleID  rating                                               text  \\\n",
       "0     1709054       5  [[(Die, ART), (sind, VAFIN), (okay, ADJD), (un...   \n",
       "1     1709054       3  [[(Qualität, NN), (und, KON), (Preis, NN), (si...   \n",
       "10     709229       5  [[(Angenehmer, NE), (Stoff, NN)], [(Füllt, NE)...   \n",
       "100    709229       5  [[(Angenehmes, NE), (und, KON), (pflegeleichte...   \n",
       "1000  9743730       1  [[(ACHTUNG, NN), (Die, ART), (Stofffarbe, NN),...   \n",
       "\n",
       "     lemmas  \n",
       "0        []  \n",
       "1        []  \n",
       "10       []  \n",
       "100      []  \n",
       "1000     []  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Lemmatize based on POS-Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from germalemma import GermaLemma\n",
    "lemmatizer = GermaLemma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[\"lemmas\"] = [[] for g in range(len(corpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 19150/19150 [01:10<00:00, 278.47it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(corpus[\"text\"]))):\n",
    "    for j in range(len(corpus[\"text\"][i])):\n",
    "        for k in range(len(corpus[\"text\"][i][j])):\n",
    "            try:\n",
    "                corpus[\"lemmas\"][i].append(lemmatizer.find_lemma(corpus[\"text\"][i][j][k][0], corpus[\"text\"][i][j][k][1]))\n",
    "            except ValueError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus.to_json(r'04pos-with-lemmas.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StyleID</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1709054</td>\n",
       "      <td>[sein, okay, dann, Preis]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[Die, ART], [sind, VAFIN], [okay, ADJD], [un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709054</td>\n",
       "      <td>[Qualität, Preis, sein, gut, leider, sein, gro...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[Qualität, NN], [und, KON], [Preis, NN], [si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>709229</td>\n",
       "      <td>[Angenehmer, Stoff, Füllt, gut, Haut]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[Angenehmer, NE], [Stoff, NN]], [[Füllt, NE]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>709229</td>\n",
       "      <td>[Angenehmes, pflegeleicht, Material, Stoff, kn...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[Angenehmes, NE], [und, KON], [pflegeleichte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>9743730</td>\n",
       "      <td>[ACHTUNG, Stofffarbe, crem, sein, Foto, abbgeb...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[ACHTUNG, NN], [Die, ART], [Stofffarbe, NN],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      StyleID                                             lemmas  rating  \\\n",
       "0     1709054                          [sein, okay, dann, Preis]       5   \n",
       "1     1709054  [Qualität, Preis, sein, gut, leider, sein, gro...       3   \n",
       "10     709229              [Angenehmer, Stoff, Füllt, gut, Haut]       5   \n",
       "100    709229  [Angenehmes, pflegeleicht, Material, Stoff, kn...       5   \n",
       "1000  9743730  [ACHTUNG, Stofffarbe, crem, sein, Foto, abbgeb...       1   \n",
       "\n",
       "                                                   text  \n",
       "0     [[[Die, ART], [sind, VAFIN], [okay, ADJD], [un...  \n",
       "1     [[[Qualität, NN], [und, KON], [Preis, NN], [si...  \n",
       "10    [[[Angenehmer, NE], [Stoff, NN]], [[Füllt, NE]...  \n",
       "100   [[[Angenehmes, NE], [und, KON], [pflegeleichte...  \n",
       "1000  [[[ACHTUNG, NN], [Die, ART], [Stofffarbe, NN],...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Lower Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/19150 [00:00<?, ?it/s]C:\\Users\\laris\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "100%|██████████████████████████████████████████████████████████████████████████| 19150/19150 [1:11:40<00:00,  4.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(corpus))):\n",
    "    corpus[\"lemmas\"][i] = [word.lower() for word in corpus[\"lemmas\"][i]]\n",
    "    #corpus[\"lemmas\"][i] = [word for word in corpus[\"lemmas\"][i] if word not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus.to_json(r'05lower-pos-with-lemmas.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StyleID</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1709054</td>\n",
       "      <td>[sein, okay, dann, preis]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[Die, ART], [sind, VAFIN], [okay, ADJD], [un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709054</td>\n",
       "      <td>[qualität, preis, sein, gut, leider, sein, gro...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[Qualität, NN], [und, KON], [Preis, NN], [si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>709229</td>\n",
       "      <td>[angenehmer, stoff, füllt, gut, haut]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[Angenehmer, NE], [Stoff, NN]], [[Füllt, NE]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>709229</td>\n",
       "      <td>[angenehmes, pflegeleicht, material, stoff, kn...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[Angenehmes, NE], [und, KON], [pflegeleichte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>9743730</td>\n",
       "      <td>[achtung, stofffarbe, crem, sein, foto, abbgeb...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[ACHTUNG, NN], [Die, ART], [Stofffarbe, NN],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      StyleID                                             lemmas  rating  \\\n",
       "0     1709054                          [sein, okay, dann, preis]       5   \n",
       "1     1709054  [qualität, preis, sein, gut, leider, sein, gro...       3   \n",
       "10     709229              [angenehmer, stoff, füllt, gut, haut]       5   \n",
       "100    709229  [angenehmes, pflegeleicht, material, stoff, kn...       5   \n",
       "1000  9743730  [achtung, stofffarbe, crem, sein, foto, abbgeb...       1   \n",
       "\n",
       "                                                   text  \n",
       "0     [[[Die, ART], [sind, VAFIN], [okay, ADJD], [un...  \n",
       "1     [[[Qualität, NN], [und, KON], [Preis, NN], [si...  \n",
       "10    [[[Angenehmer, NE], [Stoff, NN]], [[Füllt, NE]...  \n",
       "100   [[[Angenehmes, NE], [und, KON], [pflegeleichte...  \n",
       "1000  [[[ACHTUNG, NN], [Die, ART], [Stofffarbe, NN],...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Remove Stopwords from Lemmas (and some others??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = [line.rstrip('\\n') for line in open('add-stopwords.txt', encoding=\"utf-8\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = remove + stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/19150 [00:00<?, ?it/s]C:\\Users\\laris\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "100%|██████████████████████████████████████████████████████████████████████████| 19150/19150 [2:49:26<00:00,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for g in tqdm(range(len(corpus))):\n",
    "    corpus[\"lemmas\"][g] = [word for word in corpus[\"lemmas\"][g] if word not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus.to_json(r'06lower-pos-with-lemmas-without-stopwords.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StyleID</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1709054</td>\n",
       "      <td>[okay, preis]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[Die, ART], [sind, VAFIN], [okay, ADJD], [un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709054</td>\n",
       "      <td>[qualität, preis, groß, größe, fallen, untersc...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[Qualität, NN], [und, KON], [Preis, NN], [si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>709229</td>\n",
       "      <td>[angenehmer, stoff, füllt, haut]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[Angenehmer, NE], [Stoff, NN]], [[Füllt, NE]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>709229</td>\n",
       "      <td>[angenehmes, pflegeleicht, material, stoff, kn...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[Angenehmes, NE], [und, KON], [pflegeleichte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>9743730</td>\n",
       "      <td>[achtung, stofffarbe, crem, foto, abbgebilden,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[ACHTUNG, NN], [Die, ART], [Stofffarbe, NN],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      StyleID                                             lemmas  rating  \\\n",
       "0     1709054                                      [okay, preis]       5   \n",
       "1     1709054  [qualität, preis, groß, größe, fallen, untersc...       3   \n",
       "10     709229                   [angenehmer, stoff, füllt, haut]       5   \n",
       "100    709229  [angenehmes, pflegeleicht, material, stoff, kn...       5   \n",
       "1000  9743730  [achtung, stofffarbe, crem, foto, abbgebilden,...       1   \n",
       "\n",
       "                                                   text  \n",
       "0     [[[Die, ART], [sind, VAFIN], [okay, ADJD], [un...  \n",
       "1     [[[Qualität, NN], [und, KON], [Preis, NN], [si...  \n",
       "10    [[[Angenehmer, NE], [Stoff, NN]], [[Füllt, NE]...  \n",
       "100   [[[Angenehmes, NE], [und, KON], [pflegeleichte...  \n",
       "1000  [[[ACHTUNG, NN], [Die, ART], [Stofffarbe, NN],...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Compress Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = corpus.lemmas.apply(pd.Series).merge(corpus, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = new.drop([\"lemmas\"], axis=1)\n",
    "topics = topics.drop([\"text\"], axis=1)\n",
    "topics = topics.drop([\"rating\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics['id'] = topics.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.melt(topics, id_vars = ['StyleID', 'id'], value_name = \"topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topics.drop([\"variable\"], axis=1)\n",
    "topics = topics.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StyleID</th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709054</td>\n",
       "      <td>1</td>\n",
       "      <td>qualität</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19151</th>\n",
       "      <td>1709054</td>\n",
       "      <td>1</td>\n",
       "      <td>preis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38301</th>\n",
       "      <td>1709054</td>\n",
       "      <td>1</td>\n",
       "      <td>groß</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57451</th>\n",
       "      <td>1709054</td>\n",
       "      <td>1</td>\n",
       "      <td>größe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76601</th>\n",
       "      <td>1709054</td>\n",
       "      <td>1</td>\n",
       "      <td>fallen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95751</th>\n",
       "      <td>1709054</td>\n",
       "      <td>1</td>\n",
       "      <td>unterschiedlich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114901</th>\n",
       "      <td>1709054</td>\n",
       "      <td>1</td>\n",
       "      <td>shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134051</th>\n",
       "      <td>1709054</td>\n",
       "      <td>1</td>\n",
       "      <td>passen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153201</th>\n",
       "      <td>1709054</td>\n",
       "      <td>1</td>\n",
       "      <td>schade</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        StyleID id            topic\n",
       "1       1709054  1         qualität\n",
       "19151   1709054  1            preis\n",
       "38301   1709054  1             groß\n",
       "57451   1709054  1            größe\n",
       "76601   1709054  1           fallen\n",
       "95751   1709054  1  unterschiedlich\n",
       "114901  1709054  1            shirt\n",
       "134051  1709054  1           passen\n",
       "153201  1709054  1           schade"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[topics[\"id\"]==\"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topics[[\"topic\", \"StyleID\", \"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics['topic_safe'] = topics['topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topics.replace({'topic_safe': {'ä': 'ae', 'ü': 'ue', 'ö': 'oe', 'ß': 'ss'}}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>StyleID</th>\n",
       "      <th>id</th>\n",
       "      <th>topic_safe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>okay</td>\n",
       "      <td>1709054</td>\n",
       "      <td>0</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qualität</td>\n",
       "      <td>1709054</td>\n",
       "      <td>1</td>\n",
       "      <td>qualitaet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angenehmer</td>\n",
       "      <td>709229</td>\n",
       "      <td>10</td>\n",
       "      <td>angenehmer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angenehmes</td>\n",
       "      <td>709229</td>\n",
       "      <td>100</td>\n",
       "      <td>angenehmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>achtung</td>\n",
       "      <td>9743730</td>\n",
       "      <td>1000</td>\n",
       "      <td>achtung</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        topic  StyleID    id  topic_safe\n",
       "0        okay  1709054     0        okay\n",
       "1    qualität  1709054     1   qualitaet\n",
       "2  angenehmer   709229    10  angenehmer\n",
       "3  angenehmes   709229   100  angenehmes\n",
       "4     achtung  9743730  1000     achtung"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Saving to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.to_csv(\"topics.csv\", sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
